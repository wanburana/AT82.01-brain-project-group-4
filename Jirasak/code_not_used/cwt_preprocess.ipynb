{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwt_preprocess.ipynb",
      "provenance": [],
      "mount_file_id": "1IFpLGNqlzGPEF6JV4UwaVLI72bYzFL_G",
      "authorship_tag": "ABX9TyMn78Mfq5lnmN4KAzmt46u5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wanburana/AT82.01-brain-project-group-4/blob/main/Jirasak/code_not_used/cwt_preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo-sC_VMi30O",
        "outputId": "00acdaf8-6ae9-4762-a5d2-726e9feae645"
      },
      "source": [
        "!pip install mne\n",
        "!gdown --id 1LoyiM9bQlrullvtoPA7X4FWhNDBGPnED\n",
        "!unzip /content/data_preprocessed_python.zip -d data_preprocessed_python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-0.24.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.24.0\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LoyiM9bQlrullvtoPA7X4FWhNDBGPnED\n",
            "To: /content/data_preprocessed_python.zip\n",
            "100% 3.30G/3.30G [00:49<00:00, 66.3MB/s]\n",
            "Archive:  /content/data_preprocessed_python.zip\n",
            " extracting: data_preprocessed_python/s01.dat  \n",
            " extracting: data_preprocessed_python/s02.dat  \n",
            " extracting: data_preprocessed_python/s03.dat  \n",
            " extracting: data_preprocessed_python/s04.dat  \n",
            " extracting: data_preprocessed_python/s05.dat  \n",
            " extracting: data_preprocessed_python/s06.dat  \n",
            " extracting: data_preprocessed_python/s07.dat  \n",
            " extracting: data_preprocessed_python/s08.dat  \n",
            " extracting: data_preprocessed_python/s09.dat  \n",
            " extracting: data_preprocessed_python/s10.dat  \n",
            " extracting: data_preprocessed_python/s11.dat  \n",
            " extracting: data_preprocessed_python/s12.dat  \n",
            " extracting: data_preprocessed_python/s13.dat  \n",
            " extracting: data_preprocessed_python/s14.dat  \n",
            " extracting: data_preprocessed_python/s15.dat  \n",
            " extracting: data_preprocessed_python/s16.dat  \n",
            " extracting: data_preprocessed_python/s17.dat  \n",
            " extracting: data_preprocessed_python/s18.dat  \n",
            " extracting: data_preprocessed_python/s19.dat  \n",
            " extracting: data_preprocessed_python/s20.dat  \n",
            " extracting: data_preprocessed_python/s21.dat  \n",
            " extracting: data_preprocessed_python/s22.dat  \n",
            " extracting: data_preprocessed_python/s23.dat  \n",
            " extracting: data_preprocessed_python/s24.dat  \n",
            " extracting: data_preprocessed_python/s25.dat  \n",
            " extracting: data_preprocessed_python/s26.dat  \n",
            " extracting: data_preprocessed_python/s27.dat  \n",
            " extracting: data_preprocessed_python/s28.dat  \n",
            " extracting: data_preprocessed_python/s29.dat  \n",
            " extracting: data_preprocessed_python/s30.dat  \n",
            " extracting: data_preprocessed_python/s31.dat  \n",
            " extracting: data_preprocessed_python/s32.dat  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXlpNLgCi-lS"
      },
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "import pywt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9VFikQtSTFO"
      },
      "source": [
        "FOLDER_PATH = '/content/data_preprocessed_python/'\n",
        "files_list = sorted(glob(FOLDER_PATH + '*'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgRLblor95iK",
        "outputId": "8b64c468-4eb0-4ee7-b804-b56b802a377b"
      },
      "source": [
        "features = []\n",
        "targets = []\n",
        "\n",
        "for i, f in (enumerate(tqdm(files_list))):\n",
        "    with open(f, 'rb') as f: \n",
        "        content = pickle.load(f, encoding='latin1')\n",
        "        data = content['data']\n",
        "        labels = content['labels']\n",
        "        \n",
        "        n_clips, n_channels, len_features = data.shape\n",
        "        \n",
        "        for j in range(n_clips):\n",
        "            features.append(data[j])\n",
        "            targets.append(labels[j])\n",
        "\n",
        "features = np.array(features) \n",
        "targets = np.array(targets)     \n",
        "\n",
        "eeg_features = features[:, :32, :] # use only eeg channels\n",
        "print(eeg_features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:05<00:00,  6.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 32, 8064)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2YkjmmCQfGP"
      },
      "source": [
        "freq = 128\n",
        "time = 63 # 60s + 3s\n",
        "baseline_time = 3 # 3 second at the start of the trial\n",
        "\n",
        "train_size = eeg_features.shape[0]\n",
        "n_channels = eeg_features.shape[1]\n",
        "seq_len = eeg_features.shape[2] - baseline_time * freq # remove baseline from the clip\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uICKB_GDxy0Q",
        "outputId": "c69ad5b9-28bb-4ae0-b388-4341bb9bc418"
      },
      "source": [
        "# STYLE 2\n",
        "# ONLY FIRST 60 FRAME?\n",
        "\n",
        "# CWT\n",
        "scales = range(1,65)\n",
        "waveletname = 'morl'\n",
        "train_size = eeg_features.shape[0]\n",
        "n_channels = eeg_features.shape[1]\n",
        "seq_len = eeg_features.shape[2]\n",
        "train_data_cwt = np.ndarray(shape=(train_size, n_channels, len(scales), seq_len))\n",
        "\n",
        "\n",
        "Fs = 128;\n",
        "Time = 63;\n",
        "frameNum = 60;\n",
        "totalScale = 64;\n",
        "exScale = 32;\n",
        "wname = 'db4';\n",
        "\n",
        "final_output = np.zeros((train_size, 1024, 60));  \n",
        "datastart = 128*3;\n",
        "datalength = 8064 - datastart;\n",
        "\n",
        "for ii in tqdm(range(0,train_size)):\n",
        "\n",
        "    output = np.zeros((n_channels, totalScale, frameNum));  \n",
        "    for jj in range(n_channels):\n",
        "        signal = eeg_features[ii, jj, : ]\n",
        "        coeff, freq = pywt.cwt(signal[datastart:], np.arange(1,totalScale+1), waveletname);\n",
        "\n",
        "        frameSize = 60//frameNum;\n",
        "        start = 0\n",
        "        for kk in range(frameNum):\n",
        "            # output[jj,:,kk] = np.sum(coeff[:,kk*Fs:kk*Fs + Fs], 1)\n",
        "            output[jj,:,kk] = np.sum(coeff[:,kk:frameSize*kk+1], 1);\n",
        "    #         start = start + frameSize;\n",
        "    #     # output[jj, :, :] = coeff_compressed\n",
        "    exoutput = output[:,8:40,:] # select only scales of 8 - 39\n",
        "    output2d = exoutput.reshape(-1, 60); # 1024, 60\n",
        "    final_output[ii,:,:] = output2d\n",
        "    \n",
        "    # if ii >= 10:\n",
        "    #     break\n",
        "np.save('/content/drive/MyDrive/AT82.01 Project/style2.npy', final_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1280/1280 [39:12<00:00,  1.84s/it]\n"
          ]
        }
      ]
    }
  ]
}